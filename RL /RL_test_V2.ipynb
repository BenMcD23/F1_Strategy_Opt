{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 1\n",
      "Current GPU: 0\n",
      "GPU Name: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "print(\"Current GPU:\", torch.cuda.current_device())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'a': 0.014524335031135222, 'b': -0.259793656959313, 'c': 1.862598802478543}, 2: {'a': 0.003404626754128564, 'b': -0.0015711251891984146, 'c': 0.8881846067091267}, 3: {'a': 0.001548857741135055, 'b': -0.010664659121802356, 'c': 1.1093883954908919}, 4: {'a': 0.003961848445711819, 'b': -0.1909778265198026, 'c': 3.2373330032404954}}\n",
      "Lap Number: 14\n",
      "Lap Time: 90.384 seconds\n",
      "Lap Time: 96.42223780729192 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71252/3996256952.py:42: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(TyreRaceData.race_id.in_(last_20_race_ids))\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from DB.models import init_db, Circuit, Season, RacingWeekend, Driver, Session, SessionResult, Lap, TyreRaceData, Team, DriverTeamSession, TeamCircuitStats\n",
    "\n",
    "# Initialize database session\n",
    "db_engine, db_session = init_db()\n",
    "\n",
    "# Fetch a specific race (e.g., 2023 Bahrain GP)\n",
    "race_weekend = db_session.query(RacingWeekend).filter_by(year=2023, round=1).first()\n",
    "race_session = db_session.query(Session).filter_by(weekend_id=race_weekend.racing_weekend_id, session_type='Race').first()\n",
    "\n",
    "# Get total laps in the race\n",
    "total_laps = db_session.query(func.max(Lap.lap_num)).filter_by(session_id=race_session.session_id).scalar()\n",
    "\n",
    "# Fetch driver's first lap to determine starting tyre\n",
    "driver_id = 12  # Example driver\n",
    "first_lap = db_session.query(Lap).filter_by(session_id=race_session.session_id, driver_id=driver_id).order_by(Lap.lap_num).first()\n",
    "initial_tyre = first_lap.tyre\n",
    "\n",
    "# Fetch the last 20 races the driver participated in\n",
    "last_20_race_ids = (\n",
    "\tdb_session.query(TyreRaceData.race_id)\n",
    "\t.filter_by(driver_id=driver_id)\n",
    "\t.order_by(TyreRaceData.race_id.desc())  # Assuming race_id is incremental\n",
    "\t.limit(20)\n",
    "\t.subquery()\n",
    ")\n",
    "\n",
    "# Fetch tyre degradation parameters for the last 20 races and average them\n",
    "tyre_data = (\n",
    "\tdb_session.query(\n",
    "\t\tTyreRaceData.tyre_type,\n",
    "\t\tfunc.avg(TyreRaceData.a).label(\"avg_a\"),\n",
    "\t\tfunc.avg(TyreRaceData.b).label(\"avg_b\"),\n",
    "\t\tfunc.avg(TyreRaceData.c).label(\"avg_c\"),\n",
    "\t)\n",
    "\t.filter(TyreRaceData.driver_id == driver_id)\n",
    "\t.filter(TyreRaceData.race_id.in_(last_20_race_ids))\n",
    "\t.group_by(TyreRaceData.tyre_type)\n",
    "\t.all()\n",
    ")\n",
    "\n",
    "# Store averaged values in dictionary\n",
    "tyre_params = {\n",
    "\ttd.tyre_type: {'a': td.avg_a, 'b': td.avg_b, 'c': td.avg_c}\n",
    "\tfor td in tyre_data\n",
    "}\n",
    "\n",
    "print(tyre_params)\n",
    "\n",
    "# Fetch team's pit time at the circuit\n",
    "dts = db_session.query(DriverTeamSession).filter_by(session_id=race_session.session_id, driver_id=driver_id).first()\n",
    "team_stats = db_session.query(TeamCircuitStats).filter_by(circuit_id=race_weekend.circut_id, team_id=dts.team_id).first()\n",
    "pit_time = team_stats.pit_time\n",
    "\n",
    "# Baseline laptime\n",
    "\n",
    "team_stats = db_session.query(TeamCircuitStats).filter_by(\n",
    "        circuit_id=race_weekend.circut_id,\n",
    "        team_id=dts.team_id\n",
    "    ).first()\n",
    "percent_diff = team_stats.quali_to_race_percent_diff  # Quali-to-race % difference\n",
    "\n",
    "quali_session = db_session.query(Session).filter_by(\n",
    "    weekend_id=race_weekend.racing_weekend_id,\n",
    "    session_type='Qualifying'\n",
    ").first()\n",
    "\n",
    "if not quali_session:\n",
    "    raise ValueError(\"No qualifying session found for this race weekend.\")\n",
    "quali_session_id = quali_session.session_id\n",
    "\n",
    "fastest_lap = db_session.query(Lap).filter(\n",
    "    Lap.session_id == quali_session_id,\n",
    "    Lap.driver_id == 12\n",
    ").order_by(Lap.lap_time.asc()).first()\n",
    "\n",
    "if not fastest_lap:\n",
    "    raise ValueError(\"No qualifying laps found for driver 12.\")\n",
    "\n",
    "print(f\"Lap Number: {fastest_lap.lap_num}\")\n",
    "print(f\"Lap Time: {fastest_lap.lap_time} seconds\")\n",
    "baseline_lap = (fastest_lap.lap_time) + (1 * percent_diff)\n",
    "print(f\"Lap Time: {baseline_lap} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "# from sb3_contrib import MaskablePPO \n",
    "# from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "# from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "class F1RaceEnv(gym.Env):\n",
    "\tdef __init__(self, total_laps, initial_tyre, tyre_params, baseline_lap, pit_time):\n",
    "\t\tsuper(F1RaceEnv, self).__init__()\n",
    "\t\t\n",
    "\t\t# Environment parameters\n",
    "\t\tself.total_laps = total_laps\n",
    "\t\tself.initial_tyre = initial_tyre\n",
    "\t\tself.tyre_params = tyre_params\n",
    "\t\tself.baseline_lap = baseline_lap\n",
    "\t\tself.pit_time = pit_time\n",
    "\t\tself.available_tyres = [1, 2, 3]  # Soft, Medium, Hard\n",
    "\t\t\n",
    "\t\t# Action space: [Pit or not, Tire choice: 0-2]\n",
    "\t\tself.action_space = spaces.MultiDiscrete([2, len(self.available_tyres)])\n",
    "\t\t\n",
    "\t\t# Observation space: [Lap Number, Tire Wear, Stint Laps, Pit Done, Remaining Race]\n",
    "\t\tself.observation_space = spaces.Box(\n",
    "\t\t\tlow=0, \n",
    "\t\t\thigh=1, \n",
    "\t\t\tshape=(5,), \n",
    "\t\t\tdtype=np.float32\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# Reset environment\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef _get_lap_time(self, tyre, stint_laps, current_lap):\n",
    "\t\tparams = self.tyre_params[tyre]\n",
    "\t\tmax_fuel_kg = 110  # Maximum fuel load in kg\n",
    "\t\tfuel_effect_per_kg = 0.03  # Lap time increase per kg of fuel\n",
    "\t\tmax_laps_race = self.total_laps  # Total laps in the race\n",
    "\t\tfuel_weight = max_fuel_kg - (current_lap - 1) * (max_fuel_kg / max_laps_race)\n",
    "\t\tfuel_correction = fuel_weight * fuel_effect_per_kg\n",
    "\n",
    "\t\tlaptime = baseline_lap + fuel_correction + (params['a'] * stint_laps**2 + params['b'] * stint_laps + params['c'])\n",
    "\n",
    "\n",
    "\t\treturn laptime\n",
    "\n",
    "\tdef _get_state(self):\n",
    "\t\tstate = [\n",
    "\t\t\tself.current_lap / self.total_laps,          # Normalized lap\n",
    "\t\t\tself.stint_laps / 20,                        # Normalized stint laps (max 20 laps/stint)\n",
    "\t\t\tfloat(self.pit_done),                        # Pit status\n",
    "\t\t\tself.current_tyre / len(self.available_tyres),  # Normalized tyre type\n",
    "\t\t\t(self.total_laps - self.current_lap) / self.total_laps  # Remaining race\n",
    "\t\t]\n",
    "\t\treturn np.array(state, dtype=np.float32)\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.current_lap = 1\n",
    "\t\tself.current_tyre = self.initial_tyre\n",
    "\t\tself.stint_laps = 1\n",
    "\t\tself.pit_done = False\n",
    "\t\tself.used_tyres = set([self.initial_tyre])  # Track used tyres\n",
    "\t\treturn self._get_state()\n",
    "\n",
    "\tdef step(self, action):\n",
    "\t\tpit, tyre_choice = action\n",
    "\t\tdone = False\n",
    "\t\treward = 0\n",
    "\t\tinfo = {}\n",
    "\n",
    "\t\t# Calculate lap time\n",
    "\t\tlap_time = self._get_lap_time(self.current_tyre, self.stint_laps, self.current_lap)\n",
    "\t\t\n",
    "\t\tif pit:\n",
    "\t\t\t# Apply pit stop penalty\n",
    "\t\t\tlap_time += self.pit_time\n",
    "\t\t\treward -= lap_time\n",
    "\n",
    "\t\t\tself.current_tyre = tyre_choice + 1  # Convert to tyre type index\n",
    "\t\t\tif self.current_tyre not in self.used_tyres:\n",
    "\t\t\t\treward += 50 # Bonus for new tyre compound\n",
    "\t\t\t\n",
    "\t\t\tself.used_tyres.add(self.current_tyre)  # Track the new tyre\n",
    "\n",
    "\t\t\tself.stint_laps = 1\n",
    "\t\t\tself.pit_done = True\n",
    "\n",
    "\t\t\tself.last_pit_lap = self.current_lap\n",
    "\n",
    "\t\telse:\n",
    "\t\t\t# Continue without pitting\n",
    "\t\t\tself.stint_laps += 1\n",
    "\t\t\treward -= lap_time\n",
    "\n",
    "\t\t\tif tyre_choice != self.current_tyre - 1:\n",
    "\t\t\t\treward -= 9999999  # Penalty for invalid tyre change attempt\n",
    "\t\t\t\n",
    "\t\t# if self.pit_done and self.current_lap - self.last_pit_lap < 5:\n",
    "   \t\t# \treward -= 50  # Penalize pitting too soon\n",
    "\n",
    "\t\t# Move to the next lap\n",
    "\t\tself.current_lap += 1\n",
    "\n",
    "\t\t# Check race completion\n",
    "\t\tif self.current_lap > self.total_laps:\n",
    "\t\t\tdone = True\n",
    "\t\t\tif not self.pit_done:\n",
    "\t\t\t\treward -= 2000  # Penalty for missing pit stop\n",
    "\t\t\t\tinfo['reason'] = 'No pit stop'\n",
    "\n",
    "\t\t\telif len(self.used_tyres) < 2:\n",
    "\t\t\t\treward -= 2000  # Penalty for not using at least two tyre compounds\n",
    "\t\t\t\tinfo['reason'] = 'Less than two tyre compounds used'\n",
    "\t\t\telse:\n",
    "\t\t\t\tinfo['reason'] = 'Finished'\n",
    "\n",
    "\t\t# Return observation, reward, done, info\n",
    "\t\treturn self._get_state(), reward, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/Individual_Project/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 57        |\n",
      "|    ep_rew_mean     | -2.01e+08 |\n",
      "| time/              |           |\n",
      "|    fps             | 557       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 57        |\n",
      "|    ep_rew_mean          | -1.95e+08 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 436       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.79     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.2e+15   |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -9.88e-07 |\n",
      "|    value_loss           | 2.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 57        |\n",
      "|    ep_rew_mean          | -1.94e+08 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 410       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.79     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1e+15     |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -5.72e-07 |\n",
      "|    value_loss           | 2.01e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 57        |\n",
      "|    ep_rew_mean          | -1.89e+08 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 404       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.79     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1e+15     |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -6.03e-07 |\n",
      "|    value_loss           | 2.11e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 57        |\n",
      "|    ep_rew_mean          | -1.92e+08 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 401       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.79     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.54e+14  |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -6.74e-07 |\n",
      "|    value_loss           | 1.97e+15  |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Initialize environment\n",
    "env = F1RaceEnv(total_laps, initial_tyre, tyre_params, baseline_lap, pit_time)\n",
    "\n",
    "# Initialize PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, device=\"cpu\")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save(\"f1_rl_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strat Optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Strategy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/Individual_Project/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lap</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>44</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>51</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>53</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>54</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>55</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>56</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>57</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>58</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lap  action\n",
       "0     2  [0, 2]\n",
       "1     3  [1, 0]\n",
       "2     4  [1, 0]\n",
       "3     5  [1, 1]\n",
       "4     6  [1, 1]\n",
       "5     7  [1, 2]\n",
       "6     8  [0, 2]\n",
       "7     9  [0, 2]\n",
       "8    10  [0, 2]\n",
       "9    11  [1, 2]\n",
       "10   12  [0, 0]\n",
       "11   13  [1, 2]\n",
       "12   14  [1, 2]\n",
       "13   15  [1, 2]\n",
       "14   16  [0, 2]\n",
       "15   17  [0, 0]\n",
       "16   18  [1, 0]\n",
       "17   19  [0, 1]\n",
       "18   20  [0, 1]\n",
       "19   21  [0, 1]\n",
       "20   22  [1, 1]\n",
       "21   23  [0, 0]\n",
       "22   24  [1, 1]\n",
       "23   25  [1, 0]\n",
       "24   26  [1, 1]\n",
       "25   27  [1, 1]\n",
       "26   28  [1, 0]\n",
       "27   29  [1, 0]\n",
       "28   30  [0, 1]\n",
       "29   31  [0, 0]\n",
       "30   32  [1, 0]\n",
       "31   33  [1, 1]\n",
       "32   34  [0, 0]\n",
       "33   35  [1, 0]\n",
       "34   36  [0, 1]\n",
       "35   37  [1, 0]\n",
       "36   38  [0, 1]\n",
       "37   39  [0, 1]\n",
       "38   40  [0, 0]\n",
       "39   41  [1, 0]\n",
       "40   42  [1, 0]\n",
       "41   43  [1, 1]\n",
       "42   44  [1, 2]\n",
       "43   45  [1, 1]\n",
       "44   46  [1, 1]\n",
       "45   47  [0, 1]\n",
       "46   48  [1, 1]\n",
       "47   49  [1, 0]\n",
       "48   50  [1, 0]\n",
       "49   51  [1, 1]\n",
       "50   52  [0, 1]\n",
       "51   53  [1, 2]\n",
       "52   54  [1, 0]\n",
       "53   55  [1, 0]\n",
       "54   56  [1, 2]\n",
       "55   57  [0, 2]\n",
       "56   58  [0, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_optimal_strategy(env, model):\n",
    "\tobs = env.reset()\n",
    "\tdone = False\n",
    "\tstrategy = []\n",
    "\twhile not done:\n",
    "\t\taction, _ = model.predict(obs)\n",
    "\t\tobs, reward, done, _ = env.step(action)\n",
    "\t\tstrategy.append({\n",
    "\t\t\t'lap': env.current_lap,\n",
    "\t\t\t'action': action\n",
    "\t\t})\n",
    "\treturn strategy\n",
    "\n",
    "# Load trained model\n",
    "model = PPO.load(\"f1_rl_model\")\n",
    "\n",
    "# Generate optimal strategy\n",
    "optimal_strategy = get_optimal_strategy(env, model)\n",
    "# Convert strategy to a Pandas DataFrame\n",
    "strategy_df = pd.DataFrame(optimal_strategy)\n",
    "\n",
    "# Ensure all rows are displayed (no truncation)\n",
    "pd.set_option('display.max_rows', None)  # No limit on the number of rows\n",
    "pd.set_option('display.width', 1000)     # Increase display width to avoid line wrapping\n",
    "\n",
    "# Print the strategy in a readable format\n",
    "print(\"Optimal Strategy:\")\n",
    "strategy_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
