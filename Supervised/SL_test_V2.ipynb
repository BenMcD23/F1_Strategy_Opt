{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from DB.models import init_db, Circuit, Season, RacingWeekend, Driver, Session, SessionResult, Lap, TyreRaceData, Team, DriverTeamSession, TeamCircuitStats\n",
    "\n",
    "# Initialize the database session\n",
    "engine, db_session = init_db()\n",
    "\n",
    "\n",
    "query = (\n",
    "    db_session.query(\n",
    "        RacingWeekend.year,\n",
    "        Circuit.circuit_name,\n",
    "        Session.session_type,\n",
    "        Lap.driver_id,\n",
    "        Lap.lap_num,\n",
    "        Lap.tyre.label(\"current_tyre\"),\n",
    "        Lap.tyre_laps,\n",
    "        Lap.lap_time,\n",
    "        Lap.position,\n",
    "        Lap.rainfall,\n",
    "        Lap.pit.label(\"pit_stop\"),\n",
    "        TeamCircuitStats.pit_time.label(\"avg_pit_time\"),\n",
    "        TeamCircuitStats.quali_to_race_percent_diff\n",
    "    )\n",
    "    .join(Session, Lap.session_id == Session.session_id)\n",
    "    .join(RacingWeekend, Session.weekend_id == RacingWeekend.racing_weekend_id)\n",
    "    .join(Circuit, RacingWeekend.circut_id == Circuit.circuit_id)\n",
    "    .join(TeamCircuitStats, Circuit.circuit_id == TeamCircuitStats.circuit_id)\n",
    "    .filter(Session.session_type == \"Race\")  # Focus on race sessions\n",
    ")\n",
    "\n",
    "data = query.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28275/379223000.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  y_pit_decisions = grouped.apply(lambda x: list(zip(x['pit_stop'], x['current_tyre'])))  # Pit stop and tyre choices\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Convert query results to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by race and driver\n",
    "grouped = df.groupby(['year', 'circuit_name', 'driver_id'])\n",
    "\n",
    "# Encode categorical variables\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder()  # Remove sparse=False\n",
    "encoded_features = encoder.fit_transform(df[['circuit_name', 'current_tyre']]).toarray()  # Convert to dense array\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['circuit_name', 'current_tyre']))\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = df[['lap_num', 'tyre_laps', 'lap_time', 'position', 'avg_pit_time', 'quali_to_race_percent_diff']]\n",
    "scaled_features = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Combine features\n",
    "X = pd.concat([pd.DataFrame(scaled_features, columns=numerical_features.columns), encoded_df], axis=1)\n",
    "\n",
    "# Labels\n",
    "y_starting_tyre = grouped['current_tyre'].first()  # Starting tyre\n",
    "y_pit_decisions = grouped.apply(lambda x: list(zip(x['pit_stop'], x['current_tyre'])))  # Pit stop and tyre choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "# Prepare input sequences\n",
    "max_laps = df['lap_num'].max()\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    # Extract features for the current group\n",
    "    seq = group[['lap_num', 'tyre_laps', 'lap_time', 'position', 'avg_pit_time', 'quali_to_race_percent_diff']].values\n",
    "    \n",
    "    # Truncate sequences longer than max_laps\n",
    "    if len(seq) > max_laps:\n",
    "        seq = seq[:max_laps]\n",
    "    \n",
    "    # Pad sequences shorter than max_laps\n",
    "    pad_width = max(0, max_laps - len(seq))  # Ensure non-negative padding\n",
    "    seq = np.pad(seq, ((0, pad_width), (0, 0)), mode='constant')  # Pad to fixed length\n",
    "    sequences.append(seq)\n",
    "    \n",
    "    # Prepare labels for the current group\n",
    "    label = list(zip(group['pit_stop'], group['current_tyre']))\n",
    "    \n",
    "    # Truncate labels longer than max_laps\n",
    "    if len(label) > max_laps:\n",
    "        label = label[:max_laps]\n",
    "    \n",
    "    # Pad labels shorter than max_laps\n",
    "    label = [(0, 0)] * (max_laps - len(label)) + label  # Pad labels\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_seq = np.array(sequences)\n",
    "y_seq = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 14:49:44.918663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-30 14:49:44.923527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-30 14:49:44.927876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 14:49:45.521444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-30 14:49:45.523880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-30 14:49:45.526228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-01-30 14:49:46.498752: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-30 14:49:46.501333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-30 14:49:46.504026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 8s 64ms/step - loss: 0.3132 - accuracy: 0.9719\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 6s 77ms/step - loss: 0.9878 - accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 6s 86ms/step - loss: 2.1055 - accuracy: 0.9833\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 3.2256 - accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 6s 76ms/step - loss: 4.3743 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 6s 81ms/step - loss: 5.5512 - accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 6.7827 - accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 4s 47ms/step - loss: 7.9907 - accuracy: 0.9828\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 9.3700 - accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 10.7883 - accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(max_laps, X_seq.shape[2]), return_sequences=True),  # Return sequences\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Now outputs a sequence\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_seq, y_seq, epochs=10, batch_size=32)\n",
    "\n",
    "model.save('model.h5')  # Saves the model in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # Flatten the true labels and predictions\n",
    "# y_true_flat = y_seq.reshape(-1, y_seq.shape[-1])  # Flatten true labels\n",
    "# y_pred_flat = model.predict(X_seq).reshape(-1, y_seq.shape[-1])  # Flatten predictions\n",
    "\n",
    "# # Convert probabilities to class labels (argmax)\n",
    "# y_true_classes = np.argmax(y_true_flat, axis=1)\n",
    "# y_pred_classes = np.argmax(y_pred_flat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # Compute the confusion matrix\n",
    "# cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# # Extract TP, FP, FN, TN\n",
    "# # Assuming binary classification (class 0 and class 1)\n",
    "# TP = cm[1, 1]  # True Positives: Correctly predicted positive class\n",
    "# FP = cm[0, 1]  # False Positives: Incorrectly predicted positive class\n",
    "# FN = cm[1, 0]  # False Negatives: Incorrectly predicted negative class\n",
    "# TN = cm[0, 0]  # True Negatives: Correctly predicted negative class\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n",
    "# print(\"\\nTrue Positives (TP):\", TP)\n",
    "# print(\"False Positives (FP):\", FP)\n",
    "# print(\"False Negatives (FN):\", FN)\n",
    "# print(\"True Negatives (TN):\", TN)\n",
    "\n",
    "# # Optionally, calculate additional metrics\n",
    "# precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "# recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "# accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "# f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# print(\"\\nPrecision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on new race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the race details\n",
    "year = 2023\n",
    "round_number = 8\n",
    "driver_id = 5\n",
    "\n",
    "# Get the racing weekend ID\n",
    "racing_weekend = (\n",
    "    db_session.query(RacingWeekend)\n",
    "    .filter_by(year=year, round=round_number)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "if not racing_weekend:\n",
    "    raise ValueError(\"Racing weekend not found!\")\n",
    "\n",
    "weekend_id = racing_weekend.racing_weekend_id\n",
    "circuit_id = racing_weekend.circut_id\n",
    "\n",
    "# Get the circuit name\n",
    "circuit_name = db_session.query(Circuit.circuit_name).filter_by(circuit_id=circuit_id).scalar()\n",
    "\n",
    "# Get the team circuit stats for the driver's team\n",
    "team_stats = (\n",
    "    db_session.query(TeamCircuitStats)\n",
    "    .join(DriverTeamSession, DriverTeamSession.team_id == TeamCircuitStats.team_id)\n",
    "    .filter(\n",
    "        DriverTeamSession.driver_id == driver_id,\n",
    "        TeamCircuitStats.circuit_id == circuit_id\n",
    "    )\n",
    "    .first()\n",
    ")\n",
    "\n",
    "if not team_stats:\n",
    "    raise ValueError(\"Team circuit stats not found!\")\n",
    "\n",
    "avg_pit_time = team_stats.pit_time\n",
    "quali_to_race_percent_diff = team_stats.quali_to_race_percent_diff\n",
    "\n",
    "# Get lap data for the race session\n",
    "race_session = (\n",
    "    db_session.query(Session)\n",
    "    .filter_by(weekend_id=weekend_id, session_type=\"Race\")\n",
    "    .first()\n",
    ")\n",
    "\n",
    "if not race_session:\n",
    "    raise ValueError(\"Race session not found!\")\n",
    "\n",
    "session_id = race_session.session_id\n",
    "\n",
    "# Query lap data for the driver\n",
    "lap_data = (\n",
    "    db_session.query(Lap)\n",
    "    .filter_by(session_id=session_id, driver_id=driver_id)\n",
    "    .order_by(Lap.lap_num.asc())\n",
    "    .all()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Extract features from lap data\n",
    "data = []\n",
    "for lap in lap_data:\n",
    "    data.append({\n",
    "        \"lap_num\": lap.lap_num,\n",
    "        \"tyre_laps\": lap.tyre_laps,\n",
    "        \"lap_time\": lap.lap_time,\n",
    "        \"position\": lap.position,\n",
    "        \"pit_stop\": lap.pit,\n",
    "        \"current_tyre\": lap.tyre,\n",
    "        \"rainfall\": lap.rainfall,\n",
    "        \"avg_pit_time\": avg_pit_time,\n",
    "        \"quali_to_race_percent_diff\": quali_to_race_percent_diff,\n",
    "        \"circuit_name\": circuit_name,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(df[['circuit_name', 'current_tyre']]).toarray()\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['circuit_name', 'current_tyre']))\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = df[['lap_num', 'tyre_laps', 'lap_time', 'position', 'avg_pit_time', 'quali_to_race_percent_diff']]\n",
    "scaled_features = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Combine features\n",
    "X = pd.concat([pd.DataFrame(scaled_features, columns=numerical_features.columns), encoded_df], axis=1)\n",
    "\n",
    "# Pad or truncate the sequence to match max_laps\n",
    "max_laps = 70  # Example value; adjust based on training data\n",
    "pad_width = max(0, max_laps - len(X))\n",
    "X_seq = np.pad(X.values, ((0, pad_width), (0, 0)), mode='constant')\n",
    "X_seq = np.expand_dims(X_seq, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 14:50:36.660118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-30 14:50:36.662101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-30 14:50:36.663470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 422ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 14:50:37.020780: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-01-30 14:50:37.022687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-01-30 14:50:37.025319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Convert probabilities to binary decisions\u001b[39;00m\n\u001b[1;32m     30\u001b[0m pit_stop_decisions \u001b[38;5;241m=\u001b[39m (predicted_pit_stops \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m tyre_choices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_tyres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming softmax output\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lap_num, pit_stop, tyre \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_laps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), pit_stop_decisions, tyre_choices):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/home/ben/Individual_Project/env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ben/Individual_Project/env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Select only the first 6 features (or the features used during training)\n",
    "X_seq = X_seq[:, :, :6]\n",
    "\n",
    "# Define the expected number of timesteps\n",
    "max_laps = 87\n",
    "\n",
    "# Adjust the number of timesteps\n",
    "if X_seq.shape[1] < max_laps:\n",
    "    # Pad if fewer timesteps\n",
    "    pad_width = max_laps - X_seq.shape[1]\n",
    "    X_seq_final = np.pad(X_seq, ((0, 0), (0, pad_width), (0, 0)), mode='constant')\n",
    "else:\n",
    "    # Truncate if more timesteps\n",
    "    X_seq_final = X_seq[:, :max_laps, :]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_seq_final)\n",
    "\n",
    "# Interpret predictions\n",
    "predicted_pit_stops = predictions[0, :, 0]  # First output: pit stop probabilities\n",
    "predicted_tyres = predictions[0, :, 1]      # Second output: tyre choice probabilities\n",
    "\n",
    "# Convert probabilities to binary decisions\n",
    "pit_stop_decisions = (predicted_pit_stops > 0.5).astype(int)\n",
    "tyre_choices = np.argmax(predicted_tyres, axis=1)  # Assuming softmax output\n",
    "\n",
    "# Print results\n",
    "for lap_num, pit_stop, tyre in zip(range(1, max_laps + 1), pit_stop_decisions, tyre_choices):\n",
    "    if lap_num <= len(lap_data):  # Only consider actual laps\n",
    "        print(f\"Lap {lap_num}:\")\n",
    "        if pit_stop:\n",
    "            print(\"  Pit stop predicted.\")\n",
    "            print(f\"  Recommended tyre: {tyre}\")\n",
    "        else:\n",
    "            print(\"  No pit stop predicted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lap_num, pit_stop, tyre in zip(range(1, max_laps + 1), pit_stop_decisions, tyre_choices):\n",
    "    if lap_num <= len(lap_data):  # Only consider actual laps\n",
    "        print(f\"Lap {lap_num}:\")\n",
    "        if pit_stop:\n",
    "            print(\"  Pit stop predicted.\")\n",
    "            print(f\"  Recommended tyre: {tyre}\")\n",
    "        else:\n",
    "            print(\"  No pit stop predicted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
