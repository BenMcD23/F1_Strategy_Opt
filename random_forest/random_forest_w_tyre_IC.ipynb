{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not predicting correctly\n",
    "\n",
    "Not a correct way as includes the laptimes, want to predict pre race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from DB.models import init_db, Circuit, Season, RacingWeekend, Driver, Session, SessionResult, Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    # initialize db connection and session\n",
    "    db_engine, db_session = init_db()\n",
    "\n",
    "    # query data from the database\n",
    "    query = db_session.query(\n",
    "        RacingWeekend.year,\n",
    "        RacingWeekend.round,\n",
    "        Circuit.circuit_name,\n",
    "        Driver.driver_name,\n",
    "        Driver.driver_short,\n",
    "        Lap.lap_num,\n",
    "        Lap.lap_time,\n",
    "        Lap.tyre,\n",
    "        Lap.pit,\n",
    "        Session.session_type\n",
    "    ).join(RacingWeekend.circuit) \\\n",
    "     .join(RacingWeekend.sessions) \\\n",
    "     .join(Session.laps) \\\n",
    "     .join(Lap.driver) \\\n",
    "     .join(RacingWeekend.season) \\\n",
    "     .all()\n",
    "\n",
    "    # convert result to list of dicts\n",
    "    data = []\n",
    "    for row in query:\n",
    "        data.append({\n",
    "            'year': row.year,\n",
    "            'round': row.round,\n",
    "            'circuit_name': row.circuit_name,\n",
    "            'driver_name': row.driver_name,\n",
    "            'driver_short': row.driver_short,\n",
    "            'lap_num': row.lap_num,\n",
    "            'lap_time': row.lap_time,\n",
    "            'tyre': row.tyre,\n",
    "            'pit': row.pit,\n",
    "            'session_type': row.session_type\n",
    "        })\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # encode 'tyre' and 'pit' as categories\n",
    "    df['tyre'] = df['tyre'].astype('category')\n",
    "\n",
    "    # one-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=['circuit_name', 'driver_name', 'driver_short', 'session_type'], drop_first=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# create the dataframe and print it\n",
    "df = create_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76573/2284921435.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['predicted_pit'] = y_pred_test[:, 0]\n",
      "/tmp/ipykernel_76573/2284921435.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['predicted_tyre'] = y_pred_test[:, 1]\n"
     ]
    }
   ],
   "source": [
    "# split data into training (2019, 2020, 2021) and testing (2022)\n",
    "train_data = df[df['year'].isin([2019, 2020, 2021])]\n",
    "test_data = df[df['year'] == 2022]\n",
    "\n",
    "# define features (X) and targets (y) for training\n",
    "X_train = train_data.drop(columns=['pit', 'tyre'])\n",
    "y_train = train_data[['pit', 'tyre']]\n",
    "\n",
    "# define features (X) and targets (y) for testing\n",
    "X_test = test_data.drop(columns=['pit', 'tyre'])\n",
    "y_test = test_data[['pit', 'tyre']]\n",
    "\n",
    "# train the multioutput random forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "multi_output_rf = MultiOutputClassifier(rf_classifier)\n",
    "multi_output_rf.fit(X_train, y_train)\n",
    "\n",
    "# predict on the entire 2022 season\n",
    "y_pred_test = multi_output_rf.predict(X_test)\n",
    "\n",
    "# add predictions to the test data\n",
    "test_data['predicted_pit'] = y_pred_test[:, 0]\n",
    "test_data['predicted_tyre'] = y_pred_test[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Pit): 0.94\n",
      "Accuracy (Tyre): 0.51\n",
      "\n",
      "Confusion Matrix (Pit):\n",
      "[[46509   970]\n",
      " [ 1833   670]]\n",
      "\n",
      "Confusion Matrix (Tyre):\n",
      "[[    0   280   464   132     0     0]\n",
      " [   86 11694  3550  2244   165    14]\n",
      " [  175  4485  7047  4608    86     1]\n",
      " [    2  1638  3038  6441    26     0]\n",
      " [    0  1450   644   597   305    17]\n",
      " [    0   506   194    93     0     0]]\n",
      "\n",
      "Classification Report (Pit):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.98      0.97     47479\n",
      "        True       0.41      0.27      0.32      2503\n",
      "\n",
      "    accuracy                           0.94     49982\n",
      "   macro avg       0.69      0.62      0.65     49982\n",
      "weighted avg       0.93      0.94      0.94     49982\n",
      "\n",
      "\n",
      "Classification Report (Tyre):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       876\n",
      "           1       0.58      0.66      0.62     17753\n",
      "           2       0.47      0.43      0.45     16402\n",
      "           3       0.46      0.58      0.51     11145\n",
      "           4       0.52      0.10      0.17      3013\n",
      "           5       0.00      0.00      0.00       793\n",
      "\n",
      "    accuracy                           0.51     49982\n",
      "   macro avg       0.34      0.29      0.29     49982\n",
      "weighted avg       0.50      0.51      0.49     49982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy for both pit and tyre\n",
    "accuracy_pit = accuracy_score(y_test['pit'], y_pred_test[:, 0])\n",
    "accuracy_tyre = accuracy_score(y_test['tyre'], y_pred_test[:, 1])\n",
    "print(f\"Accuracy (Pit): {accuracy_pit:.2f}\")\n",
    "print(f\"Accuracy (Tyre): {accuracy_tyre:.2f}\")\n",
    "\n",
    "# confusion matrix for both pit and tyre\n",
    "conf_matrix_pit = confusion_matrix(y_test['pit'], y_pred_test[:, 0])\n",
    "conf_matrix_tyre = confusion_matrix(y_test['tyre'], y_pred_test[:, 1])\n",
    "\n",
    "print(\"\\nConfusion Matrix (Pit):\")\n",
    "print(conf_matrix_pit)\n",
    "\n",
    "print(\"\\nConfusion Matrix (Tyre):\")\n",
    "print(conf_matrix_tyre)\n",
    "\n",
    "# classification report for both pit and tyre\n",
    "class_report_pit = classification_report(y_test['pit'], y_pred_test[:, 0])\n",
    "class_report_tyre = classification_report(y_test['tyre'], y_pred_test[:, 1])\n",
    "\n",
    "print(\"\\nClassification Report (Pit):\")\n",
    "print(class_report_pit)\n",
    "\n",
    "print(\"\\nClassification Report (Tyre):\")\n",
    "print(class_report_tyre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver VER - Actual Pit Stops in Race 2022 Round 6:\n",
      "        lap_num   pit decoded_tyre\n",
      "154724       14  True       MEDIUM\n",
      "154739       29  True         SOFT\n",
      "154755       45  True       MEDIUM\n",
      "\n",
      "Driver VER - Predicted Pit Stops in Race 2022 Round 6:\n",
      "        lap_num  predicted_pit decoded_tyre\n",
      "154739       29            1.0       MEDIUM\n",
      "154755       45            1.0       MEDIUM\n"
     ]
    }
   ],
   "source": [
    "# specify driver and race to analyze\n",
    "driver = 'VER'\n",
    "race_year = 2022\n",
    "race_round = 6\n",
    "\n",
    "# filter test data for the specific race and driver\n",
    "df_race_driver = test_data[(\n",
    "    test_data['session_type_Race'] == 1) &  # race sessions only\n",
    "    (test_data[f'driver_short_{driver}'] == 1) &  # driver filter (VER)\n",
    "    (test_data['year'] == race_year) &  # year filter\n",
    "    (test_data['round'] == race_round)  # round filter\n",
    "]\n",
    "\n",
    "# get the laps where the driver actually pitted\n",
    "actual_pit_laps = df_race_driver[df_race_driver['pit'] == 1][['lap_num', 'pit', 'tyre']]\n",
    "\n",
    "# get the laps where the model predicted a pit stop\n",
    "predicted_pit_laps = df_race_driver[df_race_driver['predicted_pit'] == 1][['lap_num', 'predicted_pit', 'predicted_tyre']]\n",
    "\n",
    "# define tyre mapping\n",
    "tyre_mapping = {\n",
    "    1: 'SOFT',\n",
    "    2: 'MEDIUM',\n",
    "    3: 'HARD',\n",
    "    4: 'INTERMEDIATE',\n",
    "    5: 'WET',\n",
    "}\n",
    "\n",
    "# function to decode tyre value from integer\n",
    "def decode_tyres(value):\n",
    "    return tyre_mapping.get(value, None)  # return None if no matching tyre value\n",
    "\n",
    "# apply the decoding function to actual and predicted pit laps\n",
    "actual_pit_laps['decoded_tyre'] = actual_pit_laps['tyre'].apply(decode_tyres)\n",
    "predicted_pit_laps['decoded_tyre'] = predicted_pit_laps['predicted_tyre'].apply(decode_tyres)\n",
    "\n",
    "# print actual and predicted pit stops\n",
    "print(f\"Driver {driver} - Actual Pit Stops in Race {race_year} Round {race_round}:\")\n",
    "print(actual_pit_laps[['lap_num', 'pit', 'decoded_tyre']])\n",
    "\n",
    "print(f\"\\nDriver {driver} - Predicted Pit Stops in Race {race_year} Round {race_round}:\")\n",
    "print(predicted_pit_laps[['lap_num', 'predicted_pit', 'decoded_tyre']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
